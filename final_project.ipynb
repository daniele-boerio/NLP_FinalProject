{"cells":[{"cell_type":"markdown","metadata":{"id":"52BzNTusal04"},"source":["# Creazione del dataset unito dai dataset csv"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"o7GdUaA8jcLm"},"outputs":[],"source":["import os\n","import pandas as pd\n","from transformers import GPT2LMHeadModel, GPT2Tokenizer, DataCollatorForLanguageModeling, TrainingArguments, Trainer\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import ast\n","import torch\n","import pickle"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"WsXg0eokivij"},"outputs":[],"source":["# Percorsi ai file CSV\n","recipes_path = 'Datasets\\RAW_recipes.csv'\n","interactions_path = 'Datasets\\RAW_interactions.csv'\n","\n","# Caricamento dei dataset\n","recipes_df = pd.read_csv(recipes_path)\n","interactions_df = pd.read_csv(interactions_path)\n","\n","# Visualizza le prime righe di ciascun dataset per verificare il contenuto\n","print(recipes_df.head())\n","print(interactions_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"xq0qo1wBivij"},"outputs":[],"source":["# Nomi delle colonne nei due dataset\n","print(recipes_df.columns)\n","print(interactions_df.columns)\n","\n","# Verifica delle dimensioni dei dataset\n","print(f\"Recipes dataset shape: {recipes_df.shape}\")\n","print(f\"Interactions dataset shape: {interactions_df.shape}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"Swjz_hsPivik"},"outputs":[],"source":["# Unione dei due dataset usando 'id' dal dataset delle ricette e 'recipe_id' dal dataset delle interazioni\n","merged_df = pd.merge(recipes_df, interactions_df, left_on='id', right_on='recipe_id')\n","\n","# Visualizza le prime righe del dataset unito\n","print(merged_df.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"4vHmkOxIivik"},"outputs":[],"source":["# Controlla se ci sono valori nulli nel dataset unito\n","print(merged_df.isnull().sum())\n","\n","# Analizza la distribuzione dei rating\n","print(merged_df['rating'].describe())\n","\n","# Mostra qualche esempio di ricette con rating\n","print(merged_df[['name', 'ingredients', 'rating']].head())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7RHb0-ckivik"},"outputs":[],"source":["# Rimozione di righe duplicate\n","merged_df = merged_df.drop_duplicates()\n","\n","# Verifica del numero di righe dopo la rimozione\n","print(merged_df.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"9EzHgmcLivil"},"outputs":[],"source":["# Controlla nuovamente per valori nulli\n","print(merged_df.isnull().sum())\n","\n","# Rimuovi righe con valori nulli nelle colonne cruciali (ad esempio, ingredienti, passaggi e valutazioni)\n","merged_df = merged_df.dropna(subset=['ingredients', 'steps', 'rating'])\n","\n","# Verifica di nuovo la presenza di nulli\n","print(merged_df.isnull().sum())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MjZZnZEAivil"},"outputs":[],"source":["# Salva il dataset unito\n","merged_df.to_csv('Datasets\\working_dataset.csv', index=False)\n","\n","print(\"Dataset unito e salvato con successo.\")"]},{"cell_type":"markdown","metadata":{"id":"sUX8UERZivil"},"source":["# Import del working Dataset e tokenization degli ingredienti e steps"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ggpzpi8Pjgth"},"outputs":[],"source":["import os\n","import pandas as pd\n","from transformers import GPT2LMHeadModel, GPT2Tokenizer, DataCollatorForLanguageModeling, TrainingArguments, Trainer\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import ast\n","import torch\n","import pickle"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"s-IpGkbPRo9x"},"outputs":[],"source":["# Carica il dataset unito\n","merged_df = pd.read_csv('Datasets\\working_dataset.csv')"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"7gZXh-0PXy2w"},"outputs":[],"source":["# Converti le stringhe in liste di stringhe\n","merged_df['ingredients'] = merged_df['ingredients'].apply(ast.literal_eval)\n","merged_df['steps'] = merged_df['steps'].apply(ast.literal_eval)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RPy7jBidX1zF"},"outputs":[],"source":["def format_recipe(ingredients, steps):\n","    # Concatena gli ingredienti in una stringa separata da virgole\n","    ingredients_str = ', '.join(ingredients)\n","\n","    # Concatena gli steps in una stringa separata da numeri\n","    steps_str = '. '.join([f\"{i+1}. {step}\" for i, step in enumerate(steps)])\n","\n","    # Combina tutto in una singola stringa\n","    return f\"Ingredients: {ingredients_str}. Steps: {steps_str}.\"\n","\n","# Applica la funzione a tutte le righe del dataframe\n","merged_df['formatted'] = merged_df.apply(lambda row: format_recipe(row['ingredients'], row['steps']), axis=1)\n","\n","# Converti in una lista di stringhe pronte per il training\n","formatted_recipes = merged_df['formatted'].tolist()\n","\n","print(formatted_recipes[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PoyZJF7rUGRQ"},"outputs":[],"source":["# Carica il tokenizer GPT-2\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n","\n","# aggiungo un padding token al tokenizer\n","tokenizer.pad_token = tokenizer.eos_token\n","\n","# Tokenizza le ricette formattate\n","encodings = tokenizer(formatted_recipes, truncation=True, padding=True, max_length=512, return_tensors='pt')\n","\n","# Salva encodings su un file\n","torch.save(encodings, 'encodings.pt')\n","\n","tokenizer.save_pretrained('results/tokenizer/')"]},{"cell_type":"markdown","metadata":{"id":"UGwhCzbrsLRw"},"source":["# import del tokenizer e allenamento del modello gpt2"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"yGx8l1QN-3Ke"},"outputs":[],"source":["import os\n","import pandas as pd\n","from transformers import GPT2LMHeadModel, GPT2Tokenizer, DataCollatorForLanguageModeling, TrainingArguments, Trainer\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import ast\n","import torch\n","import pickle"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2QWM-xFowe2i"},"outputs":[],"source":["# Carico il modello GPT2\n","model = GPT2LMHeadModel.from_pretrained('gpt2')\n","# Carico il tokenizer\n","tokenizer = GPT2Tokenizer.from_pretrained('results/tokenizer/')\n","# Carico encodings da file\n","encodings = torch.load('encodings.pt')\n","\n","#classe utilizzata per allenare il modello di machine learning\n","class CustomTextDataset(torch.utils.data.Dataset):\n","    #inizializzo l'istanza della classe con gli encodings\n","    def __init__(self, encodings):\n","        self.encodings = encodings\n","\n","    #Recupera un elemento dal dataset dato un indice idx\n","    def __getitem__(self, idx):\n","        return {key: val[idx].clone().detach() for key, val in self.encodings.items()}\n","\n","    #Restituisce la lunghezza del dataset\n","    def __len__(self):\n","        return len(self.encodings.input_ids)\n","\n","dataset = CustomTextDataset(encodings)\n","\n","# Configura l'allenamento\n","training_args = TrainingArguments(\n","    output_dir='results/training/',\n","    num_train_epochs=1,\n","    per_device_train_batch_size=2,\n","    warmup_steps=500,\n","    weight_decay=0.01,\n","    logging_dir='./logs',\n","    logging_steps=100,\n","    save_steps=10000,\n","    save_total_limit=2,\n",")\n","\n","# Crea un nuovo trainer e carica lo stato precedente\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=dataset,\n","    data_collator=DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"6vz0rfiv48DS"},"outputs":[],"source":["# Controlla se esiste un checkpoint altrimenti inizia da zero\n","checkpoint_dir = 'results/training/'\n","checkpoints = [os.path.join(checkpoint_dir, d) for d in os.listdir(checkpoint_dir) if d.startswith(\"checkpoint-\")]\n","checkpoints = sorted(checkpoints, key=lambda x: int(x.split('-')[-1]))\n","\n","if checkpoints:\n","    last_checkpoint = checkpoints[-1]\n","    print(f\"Riprendo l'addestramento dall'ultimo checkpoint: {last_checkpoint}\")\n","    trainer.train(resume_from_checkpoint=last_checkpoint)\n","else:\n","    print(\"Nessun checkpoint trovato, inizio un nuovo addestramento\")\n","    trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"IVrP-A5fV0hY"},"outputs":[],"source":["#salvo gli stati finali su file per poter usarli in seguito\n","model.save_pretrained('ModelGPT/model_after_train')\n","tokenizer.save_pretrained('ModelGPT/tokenizer_after_train')\n","trainer.save_state()"]},{"cell_type":"markdown","metadata":{"id":"c6SwQKaKcd8P"},"source":["# Creazione della correlazion matrix per vedere la correlazione tra ingredienti/steps/ratings"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28141,"status":"ok","timestamp":1725045270085,"user":{"displayName":"Daniele Boerio","userId":"02898891889838517817"},"user_tz":-120},"id":"Gg8qIdrDcxs7","outputId":"9f6c2c6c-ba96-4523-c223-fb1eda03fc40"},"outputs":[],"source":["import os\n","import pandas as pd\n","from transformers import GPT2LMHeadModel, GPT2Tokenizer, DataCollatorForLanguageModeling, TrainingArguments, Trainer\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import ast\n","import torch\n","import pickle"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":16622,"status":"ok","timestamp":1725045286706,"user":{"displayName":"Daniele Boerio","userId":"02898891889838517817"},"user_tz":-120},"id":"d5KMecUh3D2y"},"outputs":[],"source":["# Carica dataset\n","merged_df = pd.read_csv('Datasets\\working_dataset.csv')"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":9097,"status":"ok","timestamp":1725045295795,"user":{"displayName":"Daniele Boerio","userId":"02898891889838517817"},"user_tz":-120},"id":"T_dKepBZlK9l"},"outputs":[],"source":["# Funzione per pulire e trasformare la stringa in una lista\n","def clean_ingredient_steps_string(ingredient_str):\n","    # Rimuovere le virgolette in eccesso e trasformare la stringa in lista\n","    try:\n","        # Prima rimuovi eventuali spazi e virgolette non necessarie\n","        ingredient_str = ingredient_str.strip(\"[]\").replace(\"'\", \"\").strip()\n","\n","        # Poi, separa gli ingredienti o gli steps se sono stati convertiti in una singola stringa\n","        ingredients = [ing.strip() for ing in ingredient_str.split(',')]\n","\n","        return ingredients\n","    except Exception as e:\n","        print(f\"Errore nella pulizia dell'ingrediente: {e}\")\n","        return []\n","\n","# Applicare la funzione di pulizia su tutta la colonna 'ingredients_list' e 'steps'\n","merged_df['ingredients_list'] = merged_df['ingredients'].apply(clean_ingredient_steps_string)\n","merged_df['steps_list'] = merged_df['steps'].apply(clean_ingredient_steps_string)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1725045295795,"user":{"displayName":"Daniele Boerio","userId":"02898891889838517817"},"user_tz":-120},"id":"8oXvXqK_CMeR","outputId":"e27e1d07-e136-43fd-fdae-1fcbafc154f3"},"outputs":[],"source":["# Verifica del risultato\n","print(type(merged_df['ingredients_list'][0]))  # Controllo il tipo della colonna ingredient_list\n","print(type(merged_df['steps_list'][0]))  # Controllo il tipo della colonna steps_list\n","\n","# Verifica del risultato\n","print(merged_df['ingredients_list'][0])  # Ora dovrebbe essere una lista di stringhe\n","print(merged_df['steps_list'][0])  # Ora dovrebbe essere una lista di stringhe"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":10694,"status":"ok","timestamp":1725045306480,"user":{"displayName":"Daniele Boerio","userId":"02898891889838517817"},"user_tz":-120},"id":"OX-YQehBwGJE"},"outputs":[],"source":["# 1. Preprocessing del Testo\n","\n","# Tokenizzazione e padding per ingredients_list\n","ingredient_tokenizer = Tokenizer()\n","ingredient_tokenizer.fit_on_texts(merged_df['ingredients_list'])\n","ingredient_sequences = ingredient_tokenizer.texts_to_sequences(merged_df['ingredients_list'])\n","ingredient_maxlen = max(len(seq) for seq in ingredient_sequences)\n","ingredient_padded = pad_sequences(ingredient_sequences, maxlen=ingredient_maxlen)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":21725,"status":"ok","timestamp":1725045328197,"user":{"displayName":"Daniele Boerio","userId":"02898891889838517817"},"user_tz":-120},"id":"YXK6Nc0lwhkP"},"outputs":[],"source":["# Tokenizzazione e padding per steps_list\n","steps_tokenizer = Tokenizer()\n","steps_tokenizer.fit_on_texts(merged_df['steps_list'])\n","steps_sequences = steps_tokenizer.texts_to_sequences(merged_df['steps_list'])\n","steps_maxlen = max(len(seq) for seq in steps_sequences)\n","steps_padded = pad_sequences(steps_sequences, maxlen=steps_maxlen)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1725045328198,"user":{"displayName":"Daniele Boerio","userId":"02898891889838517817"},"user_tz":-120},"id":"es6vgmxPjtUN","outputId":"36bbf5c2-1c32-4ea1-a1b8-4eda007857b3"},"outputs":[],"source":["#stampo il valore perchè devo prendere questo valore e salvarlo dopo\n","print(f\"Lunghezza massima per gli ingredienti: {ingredient_maxlen}\")\n","print(f\"Lunghezza massima per i passi: {steps_maxlen}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6746,"status":"ok","timestamp":1725045334942,"user":{"displayName":"Daniele Boerio","userId":"02898891889838517817"},"user_tz":-120},"id":"O5v3T2rjfuGS"},"outputs":[],"source":["# Salva il tokenizer per gli ingredienti su file\n","with open('ModelClassifier/tokenizer_ingredients.pkl', 'wb') as file:\n","    pickle.dump(ingredient_tokenizer, file)\n","\n","# Salva il tokenizer per gli steps su file\n","with open('ModelClassifier/tokenizer_steps.pkl', 'wb') as file:\n","    pickle.dump(steps_tokenizer, file)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":147058,"status":"ok","timestamp":1725045622187,"user":{"displayName":"Daniele Boerio","userId":"02898891889838517817"},"user_tz":-120},"id":"pB_kx_plASux","outputId":"cc541fad-9dad-4ac4-826c-e8f5088879ba"},"outputs":[],"source":["# Mappa per ingredienti e passi\n","def get_feature_names(tokenizer, maxlen):\n","    index_word = {index: word for word, index in tokenizer.word_index.items()}\n","    return [index_word.get(i, f'unknown_{i}') for i in range(1, maxlen + 1)]\n","\n","ingredient_names = get_feature_names(ingredient_tokenizer, ingredient_maxlen)\n","steps_names = get_feature_names(steps_tokenizer, steps_maxlen)\n","\n","# Creazione di DataFrame\n","ingredients_df = pd.DataFrame(ingredient_padded, columns=ingredient_names)\n","steps_df = pd.DataFrame(steps_padded, columns=steps_names)\n","\n","# Combinazione delle caratteristiche e dei rating\n","features_df = pd.concat([ingredients_df, steps_df], axis=1)\n","features_df['rating'] = merged_df['rating']\n","\n","# Calcolo e visualizzazione delle correlazioni\n","correlation_matrix = features_df.corr()\n","rating_correlation = correlation_matrix['rating'].drop('rating')\n","sorted_correlation = rating_correlation.sort_values(ascending=False)\n","\n","print(\"Correlazione tra ingredienti, passi e valutazioni:\")\n","print(sorted_correlation)"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":268,"status":"ok","timestamp":1725045848674,"user":{"displayName":"Daniele Boerio","userId":"02898891889838517817"},"user_tz":-120},"id":"pxxzVB15vmb4"},"outputs":[],"source":["# Salva la rating_correlation in un file\n","rating_correlation.to_pickle('ModelClassifier/rating_correlation.pkl')"]},{"cell_type":"markdown","metadata":{"id":"FcVZjggeWUyc"},"source":["# Import GPT2 model e il classificatore per generare ricette per poi trovare la migliore"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2582,"status":"ok","timestamp":1725097315416,"user":{"displayName":"Daniele Boerio","userId":"02898891889838517817"},"user_tz":-120},"id":"YANRTE1UWhPd","outputId":"1c5480b8-088c-43d4-ceb9-bdeb30518297"},"outputs":[],"source":["import pandas as pd\n","from transformers import GPT2LMHeadModel, GPT2Tokenizer, DataCollatorForLanguageModeling, TrainingArguments, Trainer\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import ast\n","import torch\n","import pickle"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":5419,"status":"ok","timestamp":1725097321310,"user":{"displayName":"Daniele Boerio","userId":"02898891889838517817"},"user_tz":-120},"id":"TeM1BdYD-xf6"},"outputs":[],"source":["# Carica il modello e il tokenizer da file\n","gpt2Model = GPT2LMHeadModel.from_pretrained('ModelGPT/model_after_train')\n","tokenizer = GPT2Tokenizer.from_pretrained('ModelGPT/tokenizer_after_train')\n","\n","# Carica il classificatore da file\n","loaded_correlation = pd.read_pickle('ModelClassifier/rating_correlation.pkl')\n","\n","# Carica il tokenizer per gli ingredienti da file\n","with open('ModelClassifier/tokenizer_ingredients.pkl', 'rb') as file:\n","    tokenizer_ingredients = pickle.load(file)\n","    \n","# Carica il tokenizer per i passaggi da file\n","with open('ModelClassifier/tokenizer_steps.pkl', 'rb') as file:\n","    tokenizer_steps = pickle.load(file)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13202,"status":"ok","timestamp":1725099621333,"user":{"displayName":"Daniele Boerio","userId":"02898891889838517817"},"user_tz":-120},"id":"G-x-t-Qz64Jd","outputId":"f3b54ab4-8988-49c0-ffa8-196821a0902f"},"outputs":[],"source":["#max_new_tokens: numero massimo di nuovi token da generare\n","#temperature: Controlla la casualità delle previsioni. Un valore più basso rende il testo più deterministico, mentre un valore più alto lo rende più vario.\n","#top_k: Limita le scelte del modello ai k migliori risultati (per migliorare la qualità delle generazioni).\n","#top_p: Percentuale cumulativa di probabilità considerata per la scelta dei token. un valore alto aumenta la varietà e creatività includendo però i token meno probabili e viceversa\n","\n","\n","def generate_recipe(prompt, max_new_tokens=100, temperature=0.8, top_k=50, top_p=0.9):\n","    input_text = f\"Ingredients: {prompt}. Steps:\"\n","    input_ids = tokenizer.encode(input_text, return_tensors='pt')\n","\n","    sample_output = gpt2Model.generate(\n","        input_ids,\n","        max_new_tokens=max_new_tokens,\n","        temperature=temperature,\n","        top_k=top_k,\n","        top_p=top_p,\n","        do_sample=True,\n","        repetition_penalty=1.2,\n","        pad_token_id=tokenizer.eos_token_id,\n","        attention_mask=torch.ones_like(input_ids)\n","    )\n","\n","    generated_text = tokenizer.decode(sample_output[0], skip_special_tokens=True)\n","    generated_text = \" \".join(generated_text.split()).strip()  # Rimuovi spazi extra\n","\n","    return generated_text\n","\n","# Genera 5 ricette chiamando la funzione 5 volte\n","prompt = \"tomato, potato, milk, salt\"\n","generated_recipes = [generate_recipe(prompt) for _ in range(5)]\n","\n","# Stampa le ricette generate\n","for i, recipe in enumerate(generated_recipes, 1):\n","    print(f\"Generated Recipe {i}:\\n{recipe}\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1725099621333,"user":{"displayName":"Daniele Boerio","userId":"02898891889838517817"},"user_tz":-120},"id":"8ru5fmbtTgQM","outputId":"e032ccbb-8f5a-404c-9d0c-75cbe80b82b5"},"outputs":[],"source":["import re\n","\n","#funzione per estrarre dalle ricette generate gli ingredienti e gli steps\n","def extract_ingredients_and_steps_from_recipes(recipes):\n","    all_ingredients_lists = []\n","    all_steps_lists = []\n","\n","    for text in recipes:\n","        # Separare la sezione degli ingredienti e degli steps\n","        ingredients_section = re.search(r'Ingredients: (.+?)\\. Steps:', text)\n","        steps_section = re.search(r'Steps: (.+)', text)\n","\n","        if ingredients_section:\n","            ingredients_text = ingredients_section.group(1).strip()\n","            # Convertire gli ingredienti in una lista di stringhe\n","            ingredients_list = [ingredient.strip() for ingredient in ingredients_text.split(',') if ingredient.strip()]\n","            all_ingredients_lists.append(ingredients_list)\n","        else:\n","            all_ingredients_lists.append([])\n","\n","        if steps_section:\n","            steps_text = steps_section.group(1).strip()\n","            # Separare gli steps e rimuovere numeri e punti\n","            steps_raw = re.split(r'\\d+\\.\\s*', steps_text)  # Usa regex per separare usando numeri e punto\n","            # Filtrare e pulire gli steps\n","            steps_list = [step.strip() for step in steps_raw if step.strip()]\n","            all_steps_lists.append(steps_list)\n","        else:\n","            all_steps_lists.append([])\n","\n","    return all_ingredients_lists, all_steps_lists\n","\n","all_ingredients_lists, all_steps_lists = extract_ingredients_and_steps_from_recipes(generated_recipes)\n","\n","print(\"All Ingredients Lists:\", all_ingredients_lists)\n","print(\"All Steps Lists:\", all_steps_lists)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1725099621333,"user":{"displayName":"Daniele Boerio","userId":"02898891889838517817"},"user_tz":-120},"id":"Hn2DfLd4mv9B","outputId":"03d4b7c1-7053-4214-f7d5-1d6de2600ffc"},"outputs":[],"source":["print(all_steps_lists[0])\n","print(all_steps_lists[1])\n","print(all_steps_lists[2])\n","print(all_steps_lists[3])\n","print(all_steps_lists[4])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1725099621333,"user":{"displayName":"Daniele Boerio","userId":"02898891889838517817"},"user_tz":-120},"id":"U1CqM6DY7Pb_","outputId":"6f46a545-bacd-4c07-ea7d-34fe7d477e59"},"outputs":[],"source":["#rimuove i punti finali negli steps per poterli tokenizzare e usare dopo\n","def remove_trailing_periods_from_steps(nested_steps_list):\n","    if not all(isinstance(sublist, list) for sublist in nested_steps_list) or \\\n","       not all(isinstance(step, str) for sublist in nested_steps_list for step in sublist):\n","        raise ValueError(\"La lista deve essere una lista di liste di stringhe.\")\n","\n","    # Applica la pulizia a ciascuna sotto-lista\n","    cleaned_nested_list = [\n","        [step.strip().rstrip('.') for step in sublist]\n","        for sublist in nested_steps_list\n","    ]\n","\n","    return cleaned_nested_list\n","# Rimuovi i punti finali\n","cleaned_all_steps_lists = remove_trailing_periods_from_steps(all_steps_lists)\n","\n","# Stampa il risultato\n","for i, steps in enumerate(cleaned_all_steps_lists, 1):\n","    print(f\"Recipe {i} Steps: {steps}\")"]},{"cell_type":"code","execution_count":74,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1725099621333,"user":{"displayName":"Daniele Boerio","userId":"02898891889838517817"},"user_tz":-120},"id":"iduxPWZ2bAiH"},"outputs":[],"source":["# Tokenizzazione e padding\n","new_ingredients_seq = tokenizer_ingredients.texts_to_sequences(all_ingredients_lists)\n","new_steps_seq = tokenizer_steps.texts_to_sequences(cleaned_all_steps_lists)\n","\n","#il Calcolo della lunghezza massima per gli ingredienti e i passi è già stata fatta prima nel notebook\n","ingredient_maxlen = 43\n","steps_maxlen = 218\n","\n","# Padding\n","new_ingredients_padded = pad_sequences(new_ingredients_seq, maxlen=ingredient_maxlen)\n","new_steps_padded = pad_sequences(new_steps_seq, maxlen=steps_maxlen)"]},{"cell_type":"code","execution_count":75,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1725099621333,"user":{"displayName":"Daniele Boerio","userId":"02898891889838517817"},"user_tz":-120},"id":"TYWqLK6NwZ-c"},"outputs":[],"source":["# Mappa per ingredienti e passi\n","def get_feature_names(tokenizer, maxlen):\n","    index_word = {index: word for word, index in tokenizer.word_index.items()}\n","    return [index_word.get(i, f'unknown_{i}') for i in range(1, maxlen + 1)]\n","\n","new_ingredient_names = get_feature_names(tokenizer_ingredients, ingredient_maxlen)\n","new_steps_names = get_feature_names(tokenizer_steps, steps_maxlen)\n","\n","# Creazione di DataFrame\n","new_ingredients_df = pd.DataFrame(new_ingredients_padded, columns=new_ingredient_names)\n","new_steps_df = pd.DataFrame(new_steps_padded, columns=new_steps_names)\n","\n","# Combinazione delle caratteristiche e dei rating\n","new_features_df = pd.concat([new_ingredients_df, new_steps_df], axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":575,"status":"ok","timestamp":1725099781815,"user":{"displayName":"Daniele Boerio","userId":"02898891889838517817"},"user_tz":-120},"id":"EoJfmv4trKA3","outputId":"8d4d1414-d759-415c-a219-5e9eef4e5601"},"outputs":[],"source":["# Calcolo della stima dei rating basata sulle correlazioni\n","rating_estimates = new_features_df.dot(loaded_correlation)\n","rating_estimates = rating_estimates / loaded_correlation.abs().sum()\n","\n","print(rating_estimates)\n","print(type(rating_estimates))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":343,"status":"ok","timestamp":1725099849217,"user":{"displayName":"Daniele Boerio","userId":"02898891889838517817"},"user_tz":-120},"id":"eZukTOw54PYZ","outputId":"db7ea7da-68c5-4f3d-cfbc-314224a5ffa3"},"outputs":[],"source":["# Trova l'indice del valore massimo\n","max_index = rating_estimates.idxmax()\n","\n","print(f\"L'indice del valore massimo è: {max_index}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":568,"status":"ok","timestamp":1725099909781,"user":{"displayName":"Daniele Boerio","userId":"02898891889838517817"},"user_tz":-120},"id":"Za94_RRl9Va6","outputId":"d0fac1f2-b943-406b-9795-94d109eb1831"},"outputs":[],"source":["#ricetta con valore massimo usando la correlation matrix\n","print(generated_recipes[max_index])"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["52BzNTusal04","sUX8UERZivil","c6SwQKaKcd8P","Q-kG7k_qEAsC","19WkDm6JCyvr"],"gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"}},"nbformat":4,"nbformat_minor":0}
